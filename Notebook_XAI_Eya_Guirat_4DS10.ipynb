{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaguirat10/Explainable-AI-Workshop/blob/main/Notebook_XAI_Eya_Guirat_4DS10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Explainable AI Workshop***\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xVY6kn0at31D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Objectives:**\n",
        "\n",
        "* Build a machine learning model to predict customer churn.\n",
        "\n",
        "* Perform a global explanation of the model's behavior using an appropriate global explanation method.\n",
        "\n",
        "* Conduct a local analysis to explain individual predictions using a suitable local explanation technique.\n"
      ],
      "metadata": {
        "id": "H5WOcUbktT-1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Customer Churn dataset:**\n",
        "\n",
        "The aim is to estimate whether a bank's customers leave the bank or not.\n",
        "\n",
        "The event that defines the customer abandonment is the closing of the customer's bank account.\n",
        "\n",
        "**Data Set Story:**\n",
        "It consists of 10000 observations and 12 variables.\n",
        "Independent variables contain information about customers.\n",
        "Dependent variable refers to customer abandonment.\n",
        "**Features:**\n",
        "* Surname: Surname\n",
        "* CreditScore: Credit score\n",
        "* Geography: Country (Germany / France / Spain)\n",
        "* Gender: Gender (Female / Male)\n",
        "* Age: Age\n",
        "* Tenure: How many years of customer\n",
        "* Balance: Balance\n",
        "* NumOfProducts: Bank product used\n",
        "* HasCrCard: Credit card status (0 = No, 1 = Yes)\n",
        "* IsActiveMember: Active membership status (0 = No, 1 = Yes)\n",
        "* EstimatedSalary: Estimated salary\n",
        "* Exited: Abandoned or not? (0 = No, 1 = Yes)\n"
      ],
      "metadata": {
        "id": "mVKpM7xcqP5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "QOepv1ttYcUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49e37344-6bbc-4883-9888-e630ff411069"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m266.2/275.7 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from lime) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lime) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.12/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.6)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=c2d124cdd5d170330906d4f4949a5cb1bf08455ca51997e3997360b02464f72f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/5d/0e/4b4fff9a47468fed5633211fb3b76d1db43fe806a17fb7486a\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBKWwD0aYPMZ",
        "outputId": "d830aa54-8f6a-4544-c7e4-8666aba77ef4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explainable AI (XAI): Methods and techniques that make AI systems' decisions more transparent and interpretable to humans.\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "# Print XAI definition\n",
        "print(\"Explainable AI (XAI): Methods and techniques that make AI systems' decisions more transparent and interpretable to humans.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read data\n",
        "data = pd.read_csv('churn_problem.csv')\n",
        "data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "v0nyWt2JYTdu",
        "outputId": "d27f1235-4d37-448a-8029-6b29196c9b3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'churn_problem.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-340927551.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'churn_problem.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'churn_problem.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "yfPFTEKXsGzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['RowNumber', 'CustomerId','Surname'], axis=1)\n"
      ],
      "metadata": {
        "id": "Pmn1Ao2_f-ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "eGAgBgVJgDrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Geography']= label_encoder.fit_transform(data['Geography'])\n",
        "\n",
        "data['Geography'].unique()"
      ],
      "metadata": {
        "id": "PqlIO8V0jBlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['Gender']= label_encoder.fit_transform(data['Gender'])\n",
        "\n",
        "data['Gender'].unique()"
      ],
      "metadata": {
        "id": "NSVA5kKSjRp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "iIO7142CjX5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data = data.select_dtypes(exclude=['object'])\n"
      ],
      "metadata": {
        "id": "KmX7RM5ZkkcP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X = data.drop('Exited', axis=1)\n",
        "y = data['Exited']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oD42j3regMSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Preprocessed data shape:\", X.shape)\n",
        "print(\"Target variable distribution:\")\n",
        "print(y.value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "gsOXL4nigcyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 0 = the customer has not left (no \"Exited\")\n",
        "\n",
        "* 1 = the customer has left (yes \"Exited\")"
      ],
      "metadata": {
        "id": "Oc-GKNu8kHvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "KnXVGtf2koBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "YDu2SdqukIkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "1tvShMSdicMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretable ML"
      ],
      "metadata": {
        "id": "WRgLENBj0IIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Logistic Regression"
      ],
      "metadata": {
        "id": "SN2b-g3L1CEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Train the model\n",
        "log_reg = LogisticRegression(max_iter=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "asW6lzJg1JbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Global Explanation"
      ],
      "metadata": {
        "id": "hwnXtbav1Rk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Extract feature names and coefficients\n",
        "coefficients = log_reg.coef_[0]\n",
        "feature_importance_lr = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Coefficient\": coefficients\n",
        "}).sort_values(by=\"Coefficient\", ascending=False)\n",
        "\n",
        "feature_importance_lr\n"
      ],
      "metadata": {
        "id": "fI4LkQwM1UxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance_lr.sort_values(\"Coefficient\", ascending=True).plot(\n",
        "    x=\"Feature\", y=\"Coefficient\", kind=\"barh\", figsize=(8,6),\n",
        "    title=\"Logistic Regression Coefficients\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "X0KfK3Z31doy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this observation reveals that Geography, IsActiveMember and Gender are the main contributors to churn prediction. Positive coefficients increase the probability of churn, while negative coefficients strongly reduce churn risk. Some features such as CreditScore and EstimatedSalary have almost no linear effect, which explains why Logistic Regression performs differently from the Random Forest model."
      ],
      "metadata": {
        "id": "ievCJ_r82IUx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Local Explanation"
      ],
      "metadata": {
        "id": "HS_p9PcC1g7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "single_example = X_test.iloc[i]\n",
        "\n",
        "print(\"Selected customer data:\")\n",
        "print(single_example)\n",
        "\n",
        "# Compute contribution = feature_value * coefficient\n",
        "contribution = single_example * coefficients\n",
        "\n",
        "local_explanation = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Value\": single_example.values,\n",
        "    \"Coefficient\": coefficients,\n",
        "    \"Contribution\": contribution\n",
        "}).sort_values(by=\"Contribution\", ascending=False)\n",
        "\n",
        "local_explanation\n"
      ],
      "metadata": {
        "id": "NG_QsmMP1ls9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression provides a transparent explanation for each prediction.\n",
        "For this customer, the strongest positive factor was Age, contributing +2.03 to the log-odds of churn, while CreditScore was the strongest negative factor, contributing –1.57. Additional smaller contributions were made by Gender (–0.51), Geography (+0.25), and Balance (+0.39).\n",
        "Features such as EstimatedSalary and HasCrCard had very small or zero influence.\n",
        "This demonstrates how interpretable models allow us to understand precisely why a prediction was made for an individual case."
      ],
      "metadata": {
        "id": "Wf_a6NnO4b9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explainable ML"
      ],
      "metadata": {
        "id": "vM1kuK86yhps"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Random Forest"
      ],
      "metadata": {
        "id": "_TM90M8_3aZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_scaled = scaler.fit_transform(X_train)\n",
        "x_test_scaled = scaler.fit_transform(X_test)"
      ],
      "metadata": {
        "id": "jUDALbQ8mptR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "test_accuracy = rf_classifier.score(X_test, y_test)\n",
        "\n",
        "# print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "UCsawpxwggg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "\n",
        "# Probability predictions\n",
        "y_proba_original = rf_classifier.predict_proba(x_test_scaled)[:, 1]\n",
        "\n",
        "# ROC curve\n",
        "fpr_original, tpr_original, _ = roc_curve(y_test, y_proba_original)\n",
        "auc_original = roc_auc_score(y_test, y_proba_original)\n",
        "\n",
        "print(\"AUC (Original Random Forest):\", auc_original)\n"
      ],
      "metadata": {
        "id": "GJYWyZPw5vzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Global Explanation**"
      ],
      "metadata": {
        "id": "Xm3FoVkpjZWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Get feature importances\n",
        "importances = rf_classifier.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "# Plot top 10 important features\n",
        "top_indices = importances.argsort()[::-1][:10]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(features[top_indices][::-1], importances[top_indices][::-1], color='skyblue')\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.title(\"Global Feature Importance (Random Forest)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oELY59EUoMX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Random Forest WITHOUT Age**"
      ],
      "metadata": {
        "id": "E_Tt1V615BZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Age from features\n",
        "X_no_age = X.drop(columns=[\"Age\"])\n",
        "\n",
        "# Train-test split again\n",
        "X_train_no_age, X_test_no_age, y_train_no_age, y_test_no_age = train_test_split(\n",
        "    X_no_age, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train RF again\n",
        "rf_no_age = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_no_age.fit(X_train_no_age, y_train_no_age)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_no_age = rf_no_age.predict(X_test_no_age)\n",
        "print(classification_report(y_test_no_age, y_pred_no_age))\n"
      ],
      "metadata": {
        "id": "dOehMkB45IGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability predictions\n",
        "y_proba_no_age = rf_no_age.predict_proba(X_test_no_age)[:, 1]\n",
        "\n",
        "# ROC curve\n",
        "fpr_no_age, tpr_no_age, _ = roc_curve(y_test_no_age, y_proba_no_age)\n",
        "auc_no_age = roc_auc_score(y_test_no_age, y_proba_no_age)\n",
        "\n",
        "print(\"AUC - RF Without Age:\", auc_no_age)\n"
      ],
      "metadata": {
        "id": "u5wvVByI6nL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Random Forest WITHOUT EstimatedSalary AND CreditScore**"
      ],
      "metadata": {
        "id": "lmpxsZJd5SE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_no_salary_score = X.drop(columns=[\"EstimatedSalary\", \"CreditScore\"])\n",
        "\n",
        "X_train_ns, X_test_ns, y_train_ns, y_test_ns = train_test_split(\n",
        "    X_no_salary_score, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "rf_no_salary_score = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_no_salary_score.fit(X_train_ns, y_train_ns)\n",
        "\n",
        "y_pred_ns = rf_no_salary_score.predict(X_test_ns)\n",
        "print(classification_report(y_test_ns, y_pred_ns))\n"
      ],
      "metadata": {
        "id": "2gXgTXsF5XGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curve**"
      ],
      "metadata": {
        "id": "PIJ7r3kuCrfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "# Original RF\n",
        "plt.plot(fpr_original, tpr_original, label=f'Original RF (AUC = {auc_original:.3f})')\n",
        "\n",
        "# Without Age\n",
        "plt.plot(fpr_no_age, tpr_no_age, label=f'RF Without Age (AUC = {auc_no_age:.3f})')\n",
        "\n",
        "# Without Salary + CreditScore\n",
        "plt.plot(fpr_ns, tpr_ns, label=f'RF Without Salary+Score (AUC = {auc_ns:.3f})')\n",
        "\n",
        "# Random baseline\n",
        "plt.plot([0,1], [0,1], 'k--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve Comparison')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S1hi0_6w7N-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve below compares three Random Forest models: the original model using all features, a model without the Age feature and a model without EstimatedSalary and CreditScore.\n",
        "\n",
        "The original model performs poorly with an AUC close to 0.5, meaning it is almost equivalent to random guessing and fails to distinguish churners from non-churners. Interestingly, when the Age feature is removed, the model’s performance improves significantly (AUC ≈ 0.79), suggesting that Age may have added noise or instability despite appearing important in the global explanation. The best performance is obtained when EstimatedSalary and CreditScore are removed (AUC ≈ 0.85), showing that these two features were not useful for prediction and that removing them helps the model focus on more relevant information.\n",
        "\n",
        "Overall, this comparison highlights that eliminating certain features can greatly improve model performance, and explainability techniques help us understand which features truly contribute to reliable predictions."
      ],
      "metadata": {
        "id": "3-IL4EOXB5ia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Probability predictions\n",
        "y_proba_ns = rf_no_salary_score.predict_proba(X_test_ns)[:, 1]\n",
        "\n",
        "# ROC curve\n",
        "fpr_ns, tpr_ns, _ = roc_curve(y_test_ns, y_proba_ns)\n",
        "auc_ns = roc_auc_score(y_test_ns, y_proba_ns)\n",
        "\n",
        "print(\"AUC - RF Without Salary & CreditScore:\", auc_ns)\n"
      ],
      "metadata": {
        "id": "j1q328Gi7KXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Local Explanation**"
      ],
      "metadata": {
        "id": "dHWgzM5lwaby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Create a LIME explainer\n",
        "lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "    X_train.values,\n",
        "    feature_names=X_train.columns,\n",
        "    class_names=['No', 'Exited'],\n",
        "    mode='classification'\n",
        ")\n",
        "\n",
        "\n",
        "# # Plot the LIME explanation\n",
        "# lime_exp.as_pyplot_figure()\n"
      ],
      "metadata": {
        "id": "aLYdtS2Gj1hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demonstrating explanation stability\n",
        "instance1 = X_test.iloc[0]\n",
        "instance2 = X_test.iloc[1731]"
      ],
      "metadata": {
        "id": "fn6oKjXJplSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.iloc[0]"
      ],
      "metadata": {
        "id": "QRE1K2N4pl_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.iloc[1731]"
      ],
      "metadata": {
        "id": "HJ5-uhX-psxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LIME explanations\n",
        "exp1 = lime_explainer.explain_instance(instance1.values, rf_classifier.predict_proba, num_features=5)\n",
        "exp2 = lime_explainer.explain_instance(instance2.values, rf_classifier.predict_proba, num_features=5)\n",
        "\n",
        "print(\"LIME explanation for instance 1:\")\n",
        "print(exp1.as_list())\n",
        "print(\"\\nLIME explanation for instance 2:\")\n",
        "print(exp2.as_list())"
      ],
      "metadata": {
        "id": "a_EvYKqsqUze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate a LIME explanation for a single instance\n",
        "instance = X_test.iloc[0]\n",
        "# lime_exp = lime_explainer.explain_instance(instance.values, rf_classifier.predict_proba, num_features=10)\n"
      ],
      "metadata": {
        "id": "DXMubi15nfZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate LIME explanation for both classes\n",
        "lime_exp = lime_explainer.explain_instance(\n",
        "    instance1.values,\n",
        "    rf_classifier.predict_proba,\n",
        "    num_features=10,\n",
        "    labels=[0, 1]  # Force explanation for both classes\n",
        ")\n",
        "\n",
        "# Now display both\n",
        "for label in [0, 1]:\n",
        "    print(f\"\\nExplanation for class {lime_exp.class_names[label]}:\")\n",
        "    for feature, weight in lime_exp.as_list(label=label):\n",
        "        print(f\"{feature}: {weight}\")\n"
      ],
      "metadata": {
        "id": "X2Cn5Sq4mjgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Les valeurs positives dans une classe favorisent cette classe.\n",
        "\n",
        "Les valeurs négatives sont en faveur de l’autre classe.\n",
        "\n",
        "Les grandes valeurs absolues indiquent une forte influence sur la décision."
      ],
      "metadata": {
        "id": "OR3rutSwQTMN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Condition | Impact sur**\"Exited\"**\n",
        "\n",
        "Jeune âge → -0.1689 | Moins probable de quitter\n",
        "\n",
        "Inactif → +0.1257 | Plus probable de quitter\n",
        "\n",
        "Num produits bancaires modérés → -0.1535 | Moins probable de quitter\n",
        "\n",
        "etc. |"
      ],
      "metadata": {
        "id": "4dH_A8lrQqfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_lime_explanation(lime_exp, label, ax, class_name):\n",
        "    exp = lime_exp.as_list(label=label)\n",
        "    features = [x[0] for x in exp]\n",
        "    weights = [x[1] for x in exp]\n",
        "\n",
        "    colors = ['green' if w > 0 else 'red' for w in weights]\n",
        "\n",
        "    ax.barh(features, weights, color=colors)\n",
        "    ax.set_title(f\"Class: {class_name}\")\n",
        "    ax.axvline(0, color='black', linewidth=0.5)\n",
        "    ax.invert_yaxis()  # Highest weight on top\n",
        "\n",
        "# Create figure\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "fig.suptitle(\"LIME Explanation for Both Classes\", fontsize=16)\n",
        "\n",
        "# Plot manually for both classes\n",
        "plot_lime_explanation(lime_exp, label=0, ax=axes[0], class_name=\"No\")\n",
        "plot_lime_explanation(lime_exp, label=1, ax=axes[1], class_name=\"Exited\")\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "l-92f9W9nWD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ANN"
      ],
      "metadata": {
        "id": "MCBdaaj0DXxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "metadata": {
        "id": "X6zAzdNkDnMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler_ann = StandardScaler()\n",
        "X_train_ann = scaler_ann.fit_transform(X_train)\n",
        "X_test_ann = scaler_ann.transform(X_test)\n"
      ],
      "metadata": {
        "id": "hMo0A-RWEVZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(16, activation='relu', input_shape=(X_train_ann.shape[1],)))\n",
        "ann_model.add(Dense(8, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "XFvE3o0NEXeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "akST-LDYEZKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = ann_model.fit(X_train_ann, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=0)\n"
      ],
      "metadata": {
        "id": "frZl6RynEi4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = ann_model.evaluate(X_test_ann, y_test, verbose=0)\n",
        "print(\"ANN Test Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "aZQctHnKEp2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Global Explanation"
      ],
      "metadata": {
        "id": "_HBU5x_lEvjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X_background = shap.sample(X_train_ann, 50)\n",
        "\n",
        "pred_fn = lambda x: ann_model.predict(x).flatten()\n",
        "\n",
        "explainer_ann = shap.KernelExplainer(pred_fn, X_background)\n",
        "\n",
        "X_sample = X_test_ann[:100]\n",
        "shap_values_ann = explainer_ann.shap_values(X_sample)\n",
        "\n",
        "shap_values_fixed = np.squeeze(shap_values_ann)"
      ],
      "metadata": {
        "id": "pMPeYylREzFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap.summary_plot(shap_values_fixed, X_sample, feature_names=X.columns)"
      ],
      "metadata": {
        "id": "1j4eiOOQJtL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SHAP summary plot for the ANN model shows which features have the biggest influence on the model’s predictions for customer churn. The feature that stands out the most is NumOfProducts, which means the number of products a customer has plays a major role in how the ANN decides whether they might leave or not. When the value of NumOfProducts is high (red dots), it tends to push the prediction toward churn. Age is also an important factor: older customers usually increase the probability of churn, while younger customers decrease it. Another strong feature is IsActiveMember, where being inactive has a clear positive impact on churn. Features like Gender, Balance, and Geography show moderate influence, meaning they sometimes affect the prediction but not as consistently. On the other hand, CreditScore, EstimatedSalary, Tenure, and HasCrCard have very small SHAP values, which suggests that the ANN model does not rely heavily on them when making decisions. Overall, this plot gives a good global view of how the ANN behaves and which features matter most for predicting churn."
      ],
      "metadata": {
        "id": "veE9AllSRLah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = ann_model.evaluate(X_test_ann, y_test)\n",
        "print(acc)\n"
      ],
      "metadata": {
        "id": "FqhK0CQjMH_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Local Explanation"
      ],
      "metadata": {
        "id": "6cEBE04uIJtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "sample = X_test_ann[i:i+1]\n",
        "\n",
        "shap_values_single = explainer_ann.shap_values(sample)\n",
        "\n",
        "# Squeeze the shap_values to ensure it's 1D for a single sample\n",
        "# shap_values_single[0] will be (10, 1) before squeezing, we want (10,)\n",
        "# sample will be (1, 10) before squeezing, we want (10,)\n",
        "shap.force_plot(explainer_ann.expected_value[0],\n",
        "                shap_values_single[0].squeeze(), # Squeeze the SHAP values\n",
        "                sample.squeeze(),                # Squeeze the sample features\n",
        "                feature_names=X.columns,\n",
        "                matplotlib=True)"
      ],
      "metadata": {
        "id": "ColhNPKYIPmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('Notebook_XAI_Eya_Guirat_4DS10.ipynb') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Remove widget metadata if it exists\n",
        "if 'widgets' in data['metadata']:\n",
        "    del data['metadata']['widgets']\n",
        "\n",
        "with open('Notebook_XAI_Eya_Guirat_4DS10_fixed.ipynb', 'w') as f:\n",
        "    json.dump(data, f)\n"
      ],
      "metadata": {
        "id": "Jxl3a_DRMLkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}